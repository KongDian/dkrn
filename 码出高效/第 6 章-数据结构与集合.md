# 第 6 章 数据结构与集合

程序 = 数据结构 + 算法

## 6.1 数据结构

1. 数据结构的定义

   数据结构是指逻辑意义上的数据组织方式及其相应的处理方式。

2. 数据结构的分类

   - 线性结构
   - 树结构
   - 图结构
   - 哈希结构

## 6.2 集合框架图

框架图中主要分为两类：第一类是按照单个元素存储的 Collection，在继承树中 Set 和 List 都实现了 Collection 接口；第二类是按照 Key-Value 存储的 Map。

![Java 集合框架图](https://www.runoob.com/wp-content/uploads/2014/01/2243690-9cd9c896e0d512ed.gif)

Collection 相关的 4 条线是 List、Queue、Set、Map。

ArrayList 非线程安全，快速随机访问，插入删除很慢。LinkedList 快速插入删除，随机访问很慢，内存使用率高。



### 6.2.2 Queue 集合

queue FIFO，一端进另一端出。常用来做 Buffer。BlockingQueue 阻塞队列。



### 6.2.3 Map 集合

Key-Value 键值对的哈希结构。 HashMap 线程不安全，ConcurrentHashMap 是线程安全的。TreeMap 是 Key 有序的 Map。



### 6.2.4 Set 集合

Set 元素不能重复。常用的  HashSet、TreeSet、LinkedHashSet 。底层是一个 Value 值固定的 Map。



## 6.3 集合初始化

ArrayList 源码：

~~~java
public class ArrayList<E> extends AbstractList<E>
    implements List<E>, RandomAccess, Cloneable, java.io.Serializable
{
    private static final long serialVersionUID = 8683452581122892189L;

    /**
     * 默认数组大小
     */
    private static final int DEFAULT_CAPACITY = 10;

    /**
     * 空表
     */
    private static final Object[] EMPTY_ELEMENTDATA = {};
    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};
    transient Object[] elementData; // non-private to simplify nested class access
    private int size;


    public ArrayList(int initialCapacity) {
        if (initialCapacity > 0) {
            this.elementData = new Object[initialCapacity];
        } else if (initialCapacity == 0) {
            this.elementData = EMPTY_ELEMENTDATA;
        } else {
            throw new IllegalArgumentException("Illegal Capacity: "+
                initialCapacity);
        }
    }
    public ArrayList() {
        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
    }
    
    public void add(int index, E element) {
        rangeCheckForAdd(index);
        ensureCapacityInternal(size + 1);  // Increments modCount!!
        System.arraycopy(elementData, index, elementData, index + 1,
            size - index);
        elementData[index] = element;
        size++;
    }
    private void grow(int minCapacity) {
        // overflow-conscious code
        // 防止扩容 1.5 倍之后，超过 int 的表示范围
        int oldCapacity = elementData.length;
        int newCapacity = oldCapacity + (oldCapacity >> 1);
        if (newCapacity - minCapacity < 0)
            newCapacity = minCapacity;
        if (newCapacity - MAX_ARRAY_SIZE > 0)
            newCapacity = hugeCapacity(minCapacity);
        // minCapacity is usually close to size, so this is a win:
        elementData = Arrays.copyOf(elementData, newCapacity);
    }
    
    private void ensureCapacityInternal(int minCapacity) {
        ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
    }

    private void ensureExplicitCapacity(int minCapacity) {
        modCount++;
        // overflow-conscious code
        if (minCapacity - elementData.length > 0)
            grow(minCapacity);
    }
    
    private static int calculateCapacity(Object[] elementData, int minCapacity) {
        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
            return Math.max(DEFAULT_CAPACITY, minCapacity);
        }
        return minCapacity;
    }
}
~~~

 ArrayList 使用无参构造器时，默认大小是 10，第一次 add 的时候分配为 10 的容量，后续扩容会调用 Array.copyOf 方法。创建新数组再复制。有 OOM 的风险。需要合理设置初始容量的大小。

HashMap 扩容需要重建 Hash 表，非常影响性能。 HashMap 有两个重要参数：Capacity 和 Load Factor。Capacity 决定存储容量大小，默认 16；而 Load Factor 决定填充比例，一般使用默认的 0.75。基于俩个的乘积，HashMap 所有 threshold 表示 HashMap 能放入的元素个数。HashMap 的容量不会在 new 的时候分配，而是在第一次 put 的时候创建。如果在初始化的时候指定了 initialCapacity，会计算出比 initialCapacity 大的 2 的幂存入 threshold 。



## 6.4 数组与集合



数组容量是固定的。数组容量为负数编译通过，但运行会抛出异常：NegativeArraySizeException。 Vector 线程安全。ArrayList 线程不安全。

数组遍历优先推荐使用 foreach 方式。

Arrays.asList() 返回的 List 不能使用其修改集合的相关方法，可以通过 set 修改原位置的元素，但是不能进行修改元素个数的操作。asList 返回的是一个 Arrays 的内部类，没有实现相关方法。

使用数组转集合可以使用 java.util.ArrayList 直接创建一个新集合。

~~~java
List<Object> objectList = new java.util.ArrayList<>(Arrays.asList(array));
~~~

使用集合 toArray（）方法 会使泛型丢失。使用 toArray（T[] array）方法时，若传入数组小于 List 大小，数组将被弃用。一般传入数组大小等于 List 相等时性能最佳。否则会降低性能，浪费空间。



## 6.5 集合与泛型



List<?> 是一个泛型，在没有赋值之前可以接受任何集合类型赋值，赋值之后就不能即便添加元素了。但是可以 remove 或者 clear

List<? extends T> 可以赋值任何 T 及 T 子类的集合，上界为 T。<? super T> 可以赋值给 T 及 T 的父类的集合，下界为 T。extends 的场景是 put 功能受限，而 super 的场景是 get 功能受限。



## 6.6 元素比较



### 6.6.1 Comparable 和 Comparator 

Comparable 是自己和自己比，Comparator 是第三方比较器。

约定俗成，不管是 Comparable 还是 Comparator，小于返回  -1，等于返回 0，大于的情况返回 1。



### 6.6.2 hashCode 和 equals

若 两个对象 hashCode 不同直接判断 Objects 不同，跳过 equals。如果 hashCode 相同，还需要调用一次 equals。

Object 类定义中对 hashCode 和 equals 要求如下：

1. 若两个对象的 equals 的结果为 true，则两个对象的 hashCode 返回结果也必须相同。
2. 任何时候覆写 equals，都必须同时覆写 hashCode。



## 6.7 fail-fast 机制

它是一种集合遍历时操作时的一种错误检测机制，在遍历中途出现意外的修改时，通过 unchecked 异常暴力地反馈出来。这种机制通常出现在多线程环境下，当前线程会维护一个计数比较器，即 expectModCount，记录已经修改的次数。在进入遍历前，会把实时修改次数赋值给 expectModCount ，如果这两个值不相等，则抛出异常。java.util 下的集合都是 fail-fast，而 concurrent 包中的集合类都是 fail-safe。与 fail-fast 不同，fail-safe 只有对于刚开始遍历就被打断的情景。
  在使用 Iterator 机制进行遍历时的删除，如果是多线程并发，需要在 Iterator 遍历时加锁。或者使用并发容器 CopyOnWriteArrayList 代替 ArrayList。使用 COW时需要注意两点：第一，尽量设置合理的容器初始值，它的扩容代价较大。第二，使用批量添加或删除方法。



## 6.8 Map 类集合

Map 类的特点：

- Map 拥有更好的性能。
- 没有重复的 Key，可以有重复的 Value。
- Value 可以是 List、Map、Set 类等。
- KV 是否允许为 null，以实现类约束为准。

Map 可以返回所有的 Key，返回所有的 Value，返回所有的 KV 键值对。

~~~java
Set<K> keySet();
Collection<V> values();
Set<Map.Entry<K,V>> entrySet();
~~~

通常这些试图支持清除操作，但是修改和增加元素会抛出异常，没有实现 add 操作，当是实现了 remove，clear 等操作。

| Map 集合类        | Key           | Value         | Super       | JDK  | 说明                          |
| :---------------- | ------------- | :------------ | :---------- | ---- | ----------------------------- |
| HashTable         | 不允许为 null | 不允许为 null | Dictionary  | 1.0  | 线程安全（过时）              |
| ConcurrentHashMap | 不允许为 null | 不允许为 null | AbstractMap | 1.5  | 锁分段或CAS（JDK8及以上）     |
| TreeMap           | 不允许为 null | 允许为 null   | AbstractMap | 1.2  | 线程不安全                    |
| HashMap           | 允许为 null   | 允许为 null   | AbstractMap | 1.2  | 线程不安全（resize 死链问题） |

### 6.8.1 红黑树

1. 树（Tree）

   树结构的特点：

   （1） 一个节点，即只有根节点也是一棵树

   （2）其中任何一个节点与下面所有节点构成的树称为子树。

   （3）根节点没有父节点，而叶子节点没有子节点。

   （4）除根节点外，任何节点有且仅有一个父节点。

   （5）任何节点都可以有 0 ~ n 个子节点。

2. 平衡二叉树

   平衡二叉树的性质如下：

   （1）树的左右高度差不能超过 1.

   （2）任何往下递归的左子树与右子树，必须符合第一条性质。

   （3）没有任何节点的空树或只有根节点的树也是平衡二叉树。

3. 二叉查找树

   二叉查找树要求：对于任意节点来说，它的左子树所有节点的值都小于它，而它的右子树上所有的节点的值都大于它。

   遍历所有节点的常有方法有三种： 前序遍历、中序遍历、后序遍历。规律如下：

   （1） 在任何递归子树中，左节点一定在右节点之前先遍历。

   （2）前序、中序、后序，仅指根节点在遍历时的位置顺序。

4. AVL 树

   AVL 树一种平衡二叉查找树，增加和删除节点后通过树形的旋转重新达到平衡。

   右旋时以某个节点为中心，将它沉入当前右子节点的位置，而让当前左子节点作为新的根节点，也称顺时针旋转；

   左旋时以某个节点为中心，将它沉入当前左子节点的位置，而让当前右子节点作为新的根节点，也称逆时针旋转

5. 红黑树

   红黑树又称为二叉B树。主要特征是在每一个节点增加一个属性来表示节点颜色，可以是红色，也可以是黑色。

   在进行节点插入和节点删除时，通过特定点旋转来保持自身平衡。红黑树并不追求所有递归子树的高度差不超过 1，而是保证从根节点到页尾的最长路径不超过最短路径的 2倍，所以最坏运行时也是 O(log n)。本质上还是二叉查找树，额外引入 5 个约束条件：

   （1）节点只能是红色或者黑色

   （2）根节点必须是黑色

   （3）所有 NIL 节点都是黑色

   （4）一条路径上不能出现相邻的两个红色节点

   （5）在任何递归子树内，根节点到叶子节点的所有路径上包含相同数目的黑色节点。

     NIL: Nothing In Leaf，是红黑树中特殊的存在，即在叶子节点上不存在的两个虚拟节点，默认是黑色的。

   总结：有红必有黑，红红不相连。红黑树的任何旋转在 3次之内均可完成。

6. 红黑树与 AVL 的比较

   任意节点的黑深度是指当前节点到 NIL 途径的黑色节点个数。对于任意包含 n 个节点的红黑树而言，它的节点高度都满足：Black Depth >= height / 2 。也就是说，对于任意高度节点而言，它的节点高度 h<= 2log(n+1) 。

   在插入节点时，红黑树与 AVL 都能在 至多两次旋转内恢复平衡。在删除时，红黑树只追求大致的平衡，能在至多三次内恢复平衡，AVL 至多需要 O(log n)。

### 6.8.2 TreeMap

Key 有序不可重复，不能为 null。必需实现 Comparable 或提供额外的比较器 Comparator。

TreeMap 依靠 Comparable 或 Comparator 实现 Key 去重。TreeMap 对 Key 进行排序，调用如下方法：

~~~java
    final int compare(Object k1, Object k2) {
        return comparator==null ? ((Comparable<? super K>)k1).compareTo((K)k2)
            : comparator.compare((K)k1, (K)k2);
    }
~~~

 如果 comparator 不为 null，优先使用 comparator 的 compare 方法；如果为 null，则使用 Key 实现的自然排序 Comparable 接口的 compareTo 方法。两者都无法满足，则抛出异常。

基于红黑树实现的 TreeMap 提供了平均和最坏复杂度均为 O(log n) 的增删改查操作，并且实现了 NavigableMap 接口，该集合最大的特点是 Key 的有续性。

~~~java
public class TreeMap<K,V>
    extends AbstractMap<K,V>
    implements NavigableMap<K,V>, Cloneable, java.io.Serializable{
    // 排序使用比较器
    private final Comparator<? super K> comparator;
    // 根节点
    private transient Entry<K,V> root;
    
    private static final boolean RED   = false;
    private static final boolean BLACK = true;
    // TreeMap 的内部类，存储红黑树节点的载体类
    static final class Entry<K,V> implements Map.Entry<K,V> {
        K key;
        V value;
        // 指向左子树
        Entry<K,V> left;
        // 指向右子树
        Entry<K,V> right;
        // 指向父节点
        Entry<K,V> parent;
        // 节点颜色，默认黑色
        boolean color = BLACK;
    }
}
~~~

TreeMap 在插入节点前，需要明确三个条件：

（1）需要调整的节点总是红色的。

（2）如果插入新节点的父亲节点是黑色的，无须调整。

（3）如果插入的新节点的父亲节点是红色的，因为红黑树规定不能出现相邻两个红色节点，所以进入循环体判断，或重新作色，或左右旋转，最终达到红黑树的五个条件，退出条件如下：

~~~java
while(x != null && x != root && x.parent.color == RED){...}
~~~

如果是根节点，则直接退出，设置为黑色即可；如果不是根节点，并且父节点为红色，会一直进行调整，直到退出循环。

TreeMap 的插入操作就是按 Key 的对比往下遍历，大于比较节点值向右走，小于比较节点值就往左走，无须关心节点颜色与树的平衡，后续会重新着色和旋转，保持红黑树特性。

~~~java
    public V put(K key, V value) {
        // t 为当前节点，先把 TreeMap 的根节点 root 引用赋值给当前节点
        Entry<K,V> t = root;
        if (t == null) {
            // 预检 Key 是否可以比较
            compare(key, key); // type (and possibly null) check
			// 使用 KV 构造出新的 Entry 对象，其中第三个参数是 parent，根节点没有父节点
            root = new Entry<>(key, value, null);
            size = 1;
            modCount++;
            return null;
        }
        // cmp 用来接收比较结果
        int cmp;
        Entry<K,V> parent;
        // 根据二叉查找树的特性，找到新节点插入的合适位置
        Comparator<? super K> cpr = comparator;
        if (cpr != null) {
            // 循环的目标：根据参数 Key 与当前节点的 Key 不断进行比较
            do {
                // 当前节点赋值给父亲节点，故从根节点开始遍历比较
                parent = t;
                // 比较输入的参数 Key 和当前节点 Key 的大小
                cmp = cpr.compare(key, t.key);
                  // 参数 Key 更小，向左边走，把当前节点的引用移动到它的左子节点上
                if (cmp < 0)
                    t = t.left;
                  // 参数 Key 更小，向左边走，把当前节点的引用移动到它的右子节点上
                else if (cmp > 0)
                    t = t.right;
                // 如果相等，则会覆盖当前节点的 Value 值，并返回更新前的值
                else
                    return t.setValue(value);
            // 如果没有相等的 Key，一直会遍历到 NIL 节点为止
            } while (t != null);
        }
        // 在没有比较器的情况下，调用自然排序的 Comparable 比较
        else {
            if (key == null)
                throw new NullPointerException();
            @SuppressWarnings("unchecked")
                Comparable<? super K> k = (Comparable<? super K>) key;
            do {
                parent = t;
                cmp = k.compareTo(t.key);
                if (cmp < 0)
                    t = t.left;
                else if (cmp > 0)
                    t = t.right;
                else
                    return t.setValue(value);
            } while (t != null);
        }
        // 创建 Entry 对象，并把 parent 置入参数
        Entry<K,V> e = new Entry<>(key, value, parent);
        if (cmp < 0)
            // 如果比较结果小于 0，则成为 parent 的左孩子
            parent.left = e;
        else
            // 如果比较结果大于 0，则成为 parent 的右孩子
            parent.right = e;
        // 还需要对这个新节点进行重新着色和旋转操作，以达到平衡
        fixAfterInsertion(e);
        size++;
        modCount++;
        // 成功插入新节点后返回 null
        return null;
    }
~~~

如果一个新节点在插入时能够运行到 fixAfterInsertion() 进行着色和旋转，说明：

第一，新节点加入之前是非空树；第二，新节点的 Key 与任何节点都不相同。

~~~java

    /** From CLR */
    private void fixAfterInsertion(Entry<K,V> x) {
        // 内部类 Entry 的属性 color 默认为黑色，但新节点一律先赋值为红色
        x.color = RED;
		// 新节点是根节点或者其父节点为黑色
        // 插入红色节点不会破坏红黑树性质，无须调整
        // x 值的改变已用红色高亮显示，改变的过程是不断向上游遍历（或者内部调整）
        // 直到父亲节点为黑色，或者到达根节点
        while (x != null && x != root && x.parent.color == RED) {
            // 如果父亲是其父节点（简称爷爷）的左子节点
            if (parentOf(x) == leftOf(parentOf(parentOf(x)))) {
                // 这时，得看爷爷得右子节点（右叔）的脸色
                Entry<K,V> y = rightOf(parentOf(parentOf(x)));
                // 如果右叔是红色，此时通过局部颜色调整，就可以使子树继续满足红黑树的性质
                if (colorOf(y) == RED) {
                    setColor(parentOf(x), BLACK);
                    setColor(y, BLACK);
                    setColor(parentOf(parentOf(x)), RED);
                    x = parentOf(parentOf(x));
                // 如果右叔是黑色，则需要加入旋转
                } else {
                    // 如果 x 是父亲的右子节点，先对父亲做一次左旋操作
                    // 转化 x 是父亲的左子节点的情形
                    if (x == rightOf(parentOf(x))) {
                        // 对父亲做一次左旋操作，红色的父亲会沉入其左侧位置
                        // 将父亲赋值给 x
                        x = parentOf(x);
                        rotateLeft(x);
                    }
                    // 重新着色并对爷爷进行右旋操作
                    setColor(parentOf(x), BLACK);
                    setColor(parentOf(parentOf(x)), RED);
                    rotateRight(parentOf(parentOf(x)));
                }
            // 与上方阴影代码相反，如果父亲是爷爷的右子节点
            } else {
                // 则看左叔脸色，原理相同
                Entry<K,V> y = leftOf(parentOf(parentOf(x)));
                if (colorOf(y) == RED) {
                    setColor(parentOf(x), BLACK);
                    setColor(y, BLACK);
                    setColor(parentOf(parentOf(x)), RED);
                    x = parentOf(parentOf(x));
                } else {
                    if (x == leftOf(parentOf(x))) {
                        x = parentOf(x);
                        rotateRight(x);
                    }
                    setColor(parentOf(x), BLACK);
                    setColor(parentOf(parentOf(x)), RED);
                    rotateLeft(parentOf(parentOf(x)));
                }
            }
        }
        root.color = BLACK;
    }
~~~

colorOf() 方法返回节点颜色。根节点必然是黑色；叶子节点可能是黑色的，也可能是红色的；叶子节点下挂的两个虚节点即 NIL 节点必然是黑色的。

~~~java
    private static <K,V> boolean colorOf(Entry<K,V> p) {
        return (p == null ? BLACK : p.color);
    }

~~~

左旋和右旋代码基本一致，以左旋为例子：

~~~java
    private void rotateLeft(Entry<K,V> p) {
        // 如果参数节点不是 NIL 节点
        if (p != null) {
            // 获取 p 的右子节点
            Entry<K,V> r = p.right;
            // 将 r 的左子树设置为 p 的右子树
            p.right = r.left;
            // 若 r 的左子树不为空，则将 p 设置为 r 左子树的父亲
            if (r.left != null)
                r.left.parent = p;
            // 将 p 的父亲设置为 r 的父亲
            r.parent = p.parent;
            if (p.parent == null)
                root = r;
            else if (p.parent.left == p)
                p.parent.left = r;
            else
                p.parent.right = r;
            // 将 p 设置为 r 的左子树，将 r 设置为 p 的父亲
            r.left = p;
            p.parent = r;
        }
    }
~~~

在树的演化过程中，插入节点过程中，如果需要重新作色或旋转，存在三种情形：

（1）节点的父亲是红色，叔叔是红色，则重新作色。

（2）节点的父亲是红色，叔叔是黑色，而新节点是父亲的左节点：进行右旋。

（3）节点的父亲是红色，叔叔是黑色，而新节点是父亲的右节点：进行左旋。

TreeMap 不是线程安全集合，不能在进行多线程的之间进行共享数据的写操作。在多线程进行写操作时，需要添加互斥机制，或者把对象放在 Collections.synchronizedMap(treeMap) 中实现同步。

在 JDK7 之后的 HashMap、TreeSet、ConcurrentHashMap，也使用红黑树的方式管理节点。



### 6.8.3 HashMap

HashMap 的死锁问题及扩容数据丢失问题是慎用 HashMap 的两个主要原因。第 1 种解决方案是用 ConcurrentHashMap 代替 HashMap；第 2 种解决方案是使用 Collections.synchronizedMap(hashMap) 包装成同步集合。

为了分析死链问题，使用 JDK7 的源码来分析 HashMap 新增元素的过程：

~~~java
    public V put(K key, V value) {
        if (table == EMPTY_TABLE) {
            inflateTable(threshold);
        }
        if (key == null)
            return putForNullKey(value);
        int hash = hash(key);
        int i = indexFor(hash, table.length);
        // 通过 hashCode 返回值找到对应的数组下标位置
        // 如果 equals 结果为真，则覆盖原值，如果都为 false，则添加元素
        for (Entry<K,V> e = table[i]; e != null; e = e.next) {
            Object k;
            // 如果 Key 的 hash 相同，那么在进行如下判断
            // Key 是同一个对象或者 equals 返回为真，则覆盖原来的 Value 值
            if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
                V oldValue = e.value;
                e.value = value;
                e.recordAccess(this);
                return oldValue;
            }
        }
		// 还没有添加元素就进行 modCount++，为后续留下许多隐患
        modCount++;
        // 添加元素，注意最后一个参数 i 是 table 数组的下标
        addEntry(hash, key, value, i);
        return null;
    }


    void addEntry(int hash, K key, V value, int bucketIndex) {
        // 如果元素的个数达到 threshold 的扩容阈值且数组下标位置已经存在元素，则进行扩容
        if ((size >= threshold) && (null != table[bucketIndex])) {
            //扩容2倍，size 是实际存放元素的个数，而 length 是数组的容量大小(capacity)
            resize(2 * table.length);
            hash = (null != key) ? hash(key) : 0;
            bucketIndex = indexFor(hash, table.length);
        }
        createEntry(hash, key, value, bucketIndex);
    }
	// 插入元素时，应插入在头部，而不是尾部
    void createEntry(int hash, K key, V value, int bucketIndex) {
        // 不管原来数组对应下标元素是否为 null，都作为 Entry 的 bucketIndex 的 next 值
        Entry<K,V> e = table[bucketIndex]; (第 1 处)
        // 即使原来是链表，也把整条链都挂在新插入的节点上
        table[bucketIndex] = new Entry<>(hash, key, value, e);
        size++;
    }
~~~

如上源码，在 createEntry() 方法种，新添加的元素直接放在 slot 槽上，使新添加的元素在下次提取时可以更快速的访问到。如果两个线程同时执行到第 1 处时，那么一个线程的赋值会被另一个覆盖掉。

| 名称     | 说明                                                         |
| -------- | ------------------------------------------------------------ |
| length   | table 数组的长度                                             |
| size     | 成功通过 put 方法添加到 HashMap 中的所有元素个数             |
| hashCode | Object.hashCode() 返回的 int 值，尽可能地离散均匀分布        |
| hash     | Object.hashCode() 与当前集合地 table.length 进行位运算地结果，以确定哈希槽地位置 |

哈希对象地存放应该符合：

- 只要对象不同，hashCode 就不一样
- 只要 hashCode 不一样，得到地 hashCode 与 hashSeed 位运算的 hash 就不一样
- 只要 hash 不一样，存放在数组上的 slot 就不一样。

在 HashMap 中，每次进行 resize 操作都会将容量扩充位原来的 2 倍。

多个元素落在同一个哈希桶中就会形成链表 （JDK7 后，可能随着链表长度增加进化为红黑树）。这个链表的头节点保存在哈希槽上，所以遍历 Map 的元素从两个方向进行：第一个方向，从下标 table[0] 至 table[length-1] 遍历所有哈希槽；第二个方向，如果哈希槽上存在元素，则遍历哈希桶中所有元素。

JDK7 中 resize() 和非常重要的 transfer() 数据迁移源码：

~~~java
    void resize(int newCapacity) {
        Entry[] oldTable = table;
        int oldCapacity = oldTable.length;
        if (oldCapacity == MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return;
        }

        Entry[] newTable = new Entry[newCapacity];
        // JDK8 移除 hashSeed 计算，因为计算时会调用 Random.nextInt(). 存在性能问题
        transfer(newTable, initHashSeedAsNeeded(newCapacity));
        table = newTable;
        // 注意，MAX 是 1 << 30. 如果 1 << 31 则成 Integer 的最小值：-2147483648 
        threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);
    }

    // 从旧表迁移数据到新表。
    void transfer(Entry[] newTable, boolean rehash) {
        // 外部参数传入时，指定大小为：2 * oldTable.length
        int newCapacity = newTable.length;
        // 遍历整个数组下标
        for (Entry<K,V> e : table) {
            // 如果此 slot 上存在元素，则进行遍历，直到 e==null, 退出循环
            while(null != e) {
                Entry<K,V> next = e.next;
                // 当前元素总是直接放在数组下标的 slot 上，而不是链表最后
                if (rehash) {
                    e.hash = null == e.key ? 0 : hash(e.key);
                }
                int i = indexFor(e.hash, newCapacity);
                // 把原来 slot 上的元素作为当前元素的下一个
                e.next = newTable[i];
                // 新迁移过来的节点直接放在 slot 位置上
                newTable[i] = e;
                // 链表继续向下遍历
                e = next;
            }
        }
    }
~~~

transfer() 数据迁移方法在数组非常大时会非常消耗资源。当前线程迁移过程中，其他线程新增元素可能落在已经遍历的哈希槽上；在遍历完成后，table 数组引用指向了 newTable，这时新元素就会丢失，被垃圾回收。

如果 resize 完成，执行了 table = newTable，则后续的元素就可以在新表上进行插入操作。但是如果多个线程执行 resize，每个线程又都会  newEntry[newCapacity]，这是线程内部局部数组对象，线程之间是不可见的。迁移完成后，resize 的线程会赋值给 table 线程共享，从而覆盖其他线程操作，因此在 “新表” 中进行插入操作的对象会被无情丢弃。总结下，HashMap 在高并发场景中，新增对象丢失原因如下：

- 并发赋值时被覆盖
- 已遍历区间新增元素会丢失
- 新表被覆盖
- 迁移丢失。在迁移过程中，有并发时，next 被提前置成 null。

从 hashCode 值到落槽位置的计算

| 方法       | 说明                                                         |
| ---------- | ------------------------------------------------------------ |
| nanoTime() | long  类型，自动封装为 Long 包装类对象                       |
| hashCode() | (int)(value ^ (value >>> 32))                                |
| hash()     | 通过 HashMap 的 hashSeed 对 hashCode 进行重新计算，尽可能离散 |
| indexFor() | slot 槽的数组下标                                            |

Integer 的 hashCode() 就是本身值，而 Long 的 hashCode() 并不是本身。

死链的生成，需要明确三点：

（1） 原先没有死链的同一个 slot 上节点遍历一定能够按顺序走完。

（2）table 数组是各线程都可以共享访问的。

（3）put()、get() 和 transfer() 三种操作在运行到此拥有 slot 上，CPU 使用率会飙升。

两个线程 A 和 B，执行 transfer 方法，虽然 newTable 是局部变量，但是原先 table 中的 Entry 链表是共享的。产生问题的根源是 Entry 的 next 被并发修改。可能导致：

（1）对象丢失。

（2）两个对象互链。

（3）对象自己互链。

JDK7 是先扩容，然后进行新元素增加操作，而 JDK8 是增加元素之后扩容。

JDK8 HashMap 改进了从头节点就进行操作数据迁移的做法，采用对原先链表的头尾节点的引用，保证 “有序性”。



### 6.8.4 ConcurrentHashMap 

JDK8 对 ConcurrentHashMap 进行了改造，使用大量的 lock-free 技术来减轻因锁竞争而对性能造成的影响。

CAS (Compare And Swap)，它的原子性是由硬件保证。需要避免 ABA 问题。

典型代码如下：

~~~java
    public final int getAndAddInt(Object o, long offset, int delta) {
        int v;
        do {
            v = getIntVolatile(o, offset);
        } while (!compareAndSwapInt(o, offset, v, v + delta));
        return v;
    }
~~~

JDK11 版本的 ConcurrentHashMap 对 JDK7 的版本进行了三点改造：

（1）取消了分段锁机制，进一步降低了冲突概率。

（2）引入红黑树结构。同一个哈希槽上的元素超过一定阈值后，单向链表会改为红黑树结构。

（3）使用了更加优化的方式统计集合内的元素数量。首先，Map 原有的 size() 方法最大只能表示 2^31 - 1，ConcurrentHashMap 额外提供了 mappingCount() 方法，用来返回集合内元素数量，最大可以表示到 2^63 - 1。此外，在元素总数更新时，使用了 CAS 和多种优化以提高并发能力。

ConcurrentHashMap 相关属性定义：

~~~java
//默认为null，ConcurrentHashMap存放数据的地方，扩容时大小总是2的幂次方
//初始化发生在第一次插入操作，数组默认初始化大小为16
transient volatile Node<K,V>[] table;
 
//默认为null，扩容时新生成的数组，其大小为原数组的两倍
private transient volatile Node<>[K,V] nextTable;
 
//存储单个KV数据节点。内部有key、value、hash、next指向下一个节点
//它有4个在ConcurrentHashMap类内部定义的子类：
//TreeBin、TreeNode、ForwardingNode、ReservationNode
//前三个子类都重写了查找元素的重要方法find()
//这些节点的概念必须清晰地区分，否则极大阻碍对源码的理解
static class Node<K,V> implements Map.Entry<K,V>{...}
 
//它并不存储实际数据，维护队桶内红黑树的读写锁，存储对红黑树节点的引用
static final class TreeBin<K,V> extends Node<K,V>{...}
 
//在红黑树结构中，实际存储数据的节点
static final class TreeNode<K,V> extends Node<K,V>{...}
 
//扩容转发节点，放置此节点后，外部对原有哈希槽的操作会转发到nextTable上
static final class ForwadingNode<K,V> extends Node<K,V>{...}
 
//占位加锁节点，执行某些方法时，对其加锁，如computeIfAbsent等
static final class ReservationNode<K,V> extends Node<K,V>{...}
 
//默认为0，重要属性，用来控制table的初始化和扩容操作
//sizeCtl=-1，表示正在初始化中
//sizeCtl=-n，表示（n-1）个线程正在进行扩容中
//sizeCtl>0，初始化或扩容中需要使用的容量
//sizeCtl=0，默认值，使用默认容量进行初始化
private transient volatile int sizeCtl;
 
//集合size小于64，无论如何，都不会使用红黑树结构
//转化为红黑树还有一个条件是TREEIFY_THRESHOLD
static final int MIN_TREEIFY_CAPACITY = 64;
 
//同一个哈希桶内存储的元素个数超过此阀值时
//则将存储结构由链表转为红黑树
static final int TREEIFY_THRESHOLD = 8;
 
//同一个哈希桶内存储的元素个数小于等于此阀值时
//从红黑树退回至链表结构，因为元素个数较少时，链表更快
static final int UNTREEIFY_THRESHOLD = 6;
~~~

ConcurrentHashMap 大致存储结构：

![ConcurrentHashMap 的元素存储类型](https://img-blog.csdnimg.cn/20190201103359829.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA0NzcwNA==,size_16,color_FFFFFF,t_70)

table的长度为64，数据存储结构分为两种：链表和红黑树。当某个槽内的元素个数增加到超过8个且table的容量大于或等于64时，由链表转换为红黑树；当某个槽内的元素个数减少到6个时，由红黑树重新转回链表。链表转红黑树的过程，就是把给定顺序的元素构造成一颗红黑树的过程。需要注意的是，当table容量小于64时，只会扩容，并不会把链表转为红黑树。在转化过程中，使用同步块锁住当前槽的首元素，防止其他进程对当前槽进行增删改操作，转化完成后利用CAS替换原有链表。因为TreeBin 节点也存储了next引用，所以红黑树转量表的操作就变得非常简单，只需从 TreeBin 的 first 元素开始遍历所有的节点，并把节点从 TreeBin 类型转化为 Node 类型即可，当构造好新的链表之后，会同样利用CAS替换原有红黑树。相对来说，链表转红黑树更为复杂，流程图如下图所示：

![ConcurrentHashMap元素插入流程图](https://img-blog.csdnimg.cn/20190201104912827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA0NzcwNA==,size_16,color_FFFFFF,t_70)

触发上述存储结构转化最主要的操作就是增加元素，即put()方法。基本思想与HashMap一致，区别就是增加了锁的处理，ConcurrentHashMap元素扩容流程图如下图所示：

![ConcurrentHashMap 扩容流程图](https://img-blog.csdnimg.cn/20190201110431356.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA0NzcwNA==,size_16,color_FFFFFF,t_70)

Node 的另外两个子类：ForwardingNode 和 ReservationNode。ForwardingNode在table扩容时使用，内部记录了扩容后的table，即 nextTable。当table需要扩容时，依次遍历当前 table 中的每一个槽，如果不为null，则需要把其中所有的元素根据hash值放入扩容后的 nextTable 中，而原 table 的槽内会放置一个 ForwardingNode 节点。正如其名（forwarding 翻译为转发），此节点也会把 find() 请求转发到扩容后的 nextTable 上，而执行 put() 方法的线程如果碰到此节点，也会协助进行迁移。 

ReservationNode 在 computeIfAbsent() 及其相关方法中作为一个预留节点使用。computeIfAbsent() 方法会先判断相应的 Key 值是否已存在，如果不存在，则调用由用户实现的自定义方法来生成 value 值，组成KV键值对，随后插入此哈希集合中。在并发场景下，在从得知Key不存在到插入哈希集合的时间间隔内，为了防止哈希槽被其他线程抢占，当前线程会使用一个 ReservationNode 节点放在槽中并加锁，从而保证了线程的安全性。

无论是 JDK7 还是 JDK8，ConcurrentHashMap 的 size() 方法都只能返回一个大致数量，无法做到100%的精准，因为已经统计过的槽在size()返回最终结果前有可能又出现了变化，从而导致返回大小与实际大小存在些许差异。在多个槽的设计下，如果仅仅是为了统计元素数量而停下所有的增删操作，又会显得因噎废食。因此，ConcurrentHashMap在设计元素总数的相关更新和计算时，会最大限度地减少锁的使用，以减少线程间的竞争与互相等待。在这个设计思路下，JDK8 的   ConcurrentHashMap 对元素总数的计算又做了进一步的优化，具体表现在：在put()、remove() 和 size() 方法中，设计元素总数的更新和计算，都彻底避免了锁的使用，取而代之的是众多CAS操作。  

JDK7 版本中的 put() 方法和 remove() 方法，对于 segment 内部元素和计数器的更新，全部处于锁的保护下。如 Segment.put() 方法的第一行：

~~~java
// 经过这一行代码，能够保证前档线程取得该Segment上的锁，随后可以大胆地更新元素和
// 内部计数器
HashEntry<k> node = tryLock() ? null : scanAndLockForPut(key, hash, value);
~~~

JDK7 版本的 ConcurrentHashMap 获取集合大小的流程图：

![JDK7 版本的 ConcurrentHashMap 获取集合大小的流程图](https://img-blog.csdnimg.cn/20190201113239706.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA0NzcwNA==,size_16,color_FFFFFF,t_70)

在JDK7中，ConcurrentHashMap 在统计元素总数时已经开始避免使用锁了，毕竟加锁操作会极大地影响到其他线程对于哈希元素的修改。当经过了3次计算（2次对比）后，发现每次统计时哈希都有结构性的变化，这是它就会“气急败坏”地把所有Segment都加上所；而当自己统计完成后，才会把锁释放掉，再允许其他线程修改哈希中的元素。   

JDK8的ConcurrentHashMap给出了答案：有！前面已经分析过了，在put()中，对于哈希元素总数的更新，是置于对某个槽的锁之外的，主要会用到以下的属性：

~~~java
//记录了元素总数值，主要用在无竞争状态下
//在总数更新后，通过CAS方式直接更新这个值
private transient volatile long baseCount;
 
//一个计数器单元，维护了一个value值
static final class CounterCell{...}
 
//在竞争激烈的状态下启用，线程会把总数更新情况放到该结构内
//当竞争进一步加剧时，会通过扩容减少竞争
private transient volatile CounterCell[] counterCells;
~~~

正是借助了 baseCount 和 counterCells 两个属性，并配合多次使用CAS方法，JDK8中的ConcurrentHashMap避免了锁的使用。

- 当并发量较小时，优先使用CAS方式直接更新 baseCount。
- 当更新baseCount冲突，则会认为进入到比较激烈的竞争状态，通过启用 counterCells 减少冲突，通过CAS的方式把总数更新情况记录在 counterCells 对应的位置上。
- 如果更新 counterCells 上的某个位置时出现了多次失败，则会通过扩容 counterCells 的方式减少冲突。
- 当counterCells处在扩容期间时，会尝试更新baseCount值。

对于元素总数的统计，逻辑就非常简单了，只需让 baseCount 加上个 counterCells 内的数据，就可以得出哈希内的元素总数，整个过程完全不需要加锁。

正因为 ConcurrentHashMap 提供了高效的锁机制实现，在各种多线程应用场景中，推荐使用此集合进行KV键值对的存储与使用。